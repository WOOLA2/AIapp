import pandas as pd
import numpy as np
from scipy import stats

print("=== TASK 1: DATA GATHERING AND CLEANING ===\n")

# Try different separators to load the data correctly
separators = [';', ',', '\t', '|']
df = None

for sep in separators:
    try:
        df = pd.read_csv(r"C:\Users\Molefi\Desktop\ProjectAI\studata.csv", sep=sep)
        if df.shape[1] > 1:
            print(f"\n‚úÖ Successfully loaded with separator '{sep}'")
            print(f"Shape: {df.shape}")
            break
    except:
        continue

# If loading failed, create sample data for demonstration
if df is None or df.shape[1] <= 1:
    print("‚ùå Could not load the file with any separator. Creating sample data for demonstration...")
    np.random.seed(42)
    n_samples = 4424
    
    sample_data = {
        'Marital status': np.random.choice([1, 2, 3, 4, 5, 6], n_samples),
        'Application mode': np.random.choice([1, 2, 5, 7, 10, 15, 16, 17, 18, 26, 27, 39, 42, 43, 44, 51, 53, 57], n_samples),
        'Application order': np.random.randint(0, 10, n_samples),
        'Course': np.random.choice([33, 171, 8014, 9003, 9070, 9085, 9119, 9130, 9147, 9238, 9254, 9500, 9556, 9670, 9773, 9853, 9991], n_samples),
        'Daytime/evening attendance': np.random.choice([0, 1], n_samples),
        'Previous qualification': np.random.choice([1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 19, 38, 39, 40, 42, 43], n_samples),
        'Previous qualification (grade)': np.random.uniform(0, 200, n_samples),
        'Nacionality': np.random.choice([1, 2, 6, 11, 13, 14, 17, 21, 22, 24, 25, 26, 32, 41, 62, 100, 101, 103, 105, 108, 109], n_samples),
        "Mother's qualification": np.random.choice([1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 14, 18, 19, 22, 26, 27, 29, 30, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], n_samples),
        "Father's qualification": np.random.choice([1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 18, 19, 20, 22, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], n_samples),
        'Admission grade': np.random.uniform(0, 200, n_samples),
        'Displaced': np.random.choice([0, 1], n_samples),
        'Educational special needs': np.random.choice([0, 1], n_samples),
        'Debtor': np.random.choice([0, 1], n_samples),
        'Tuition fees up to date': np.random.choice([0, 1], n_samples),
        'Gender': np.random.choice([0, 1], n_samples),
        'Scholarship holder': np.random.choice([0, 1], n_samples),
        'Age at enrollment': np.random.randint(17, 60, n_samples),
        'International': np.random.choice([0, 1], n_samples),
        'Curricular units 1st sem (grade)': np.random.uniform(0, 20, n_samples),
        'Curricular units 2nd sem (grade)': np.random.uniform(0, 20, n_samples),
        'Unemployment rate': np.random.uniform(1, 20, n_samples),
        'Inflation rate': np.random.uniform(-2, 10, n_samples),
        'GDP': np.random.uniform(10000, 50000, n_samples),
        'Target': np.random.choice(['Dropout', 'Enrolled', 'Graduate'], n_samples, p=[0.3, 0.2, 0.5])
    }
    df = pd.DataFrame(sample_data)

print(f"\n‚úÖ FINAL DATASET SHAPE: {df.shape}")
print(f"Columns: {list(df.columns)}")
print(f"\nFirst 3 rows:")
print(df.head(3))

# ==========================
# a. MISSING VALUES ANALYSIS
# ==========================
print("\n\na. MISSING VALUES ANALYSIS")
print("=" * 50)

missing_values = df.isnull().sum()
missing_percentage = (df.isnull().sum() / len(df)) * 100

missing_info = pd.DataFrame({
    'Missing Count': missing_values,
    'Missing Percentage': missing_percentage
})

# Display only features with missing values
missing_features = missing_info[missing_info['Missing Count'] > 0]
if not missing_features.empty:
    print("Features with missing values:")
    print(missing_features)
else:
    print("‚úÖ No missing values found in the dataset")

print(f"\nTotal missing values: {df.isnull().sum().sum()}")

# ==========================
# b. OUTLIER DETECTION
# ==========================
print("\n\nb. OUTLIER DETECTION")
print("=" * 50)

# Define valid ranges for categorical features
categorical_valid_ranges = {
    'Marital status': {1, 2, 3, 4, 5, 6},
    'Application mode': {1, 2, 5, 7, 10, 15, 16, 17, 18, 26, 27, 39, 42, 43, 44, 51, 53, 57},
    'Application order': set(range(0, 10)),
    'Course': {33, 171, 8014, 9003, 9070, 9085, 9119, 9130, 9147, 9238, 9254, 9500, 9556, 9670, 9773, 9853, 9991},
    'Daytime/evening attendance\t': {0, 1},  # Note the tab character in column name
    'Previous qualification': {1, 2, 3, 4, 5, 6, 9, 10, 12, 14, 15, 19, 38, 39, 40, 42, 43},
    'Nacionality': {1, 2, 6, 11, 13, 14, 17, 21, 22, 24, 25, 26, 32, 41, 62, 100, 101, 103, 105, 108, 109},
    "Mother's qualification": {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 14, 18, 19, 22, 26, 27, 29, 30, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44},
    "Father's qualification": {1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 18, 19, 20, 22, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44},
    'Displaced': {0, 1},
    'Educational special needs': {0, 1},
    'Debtor': {0, 1},
    'Tuition fees up to date': {0, 1},
    'Gender': {0, 1},
    'Scholarship holder': {0, 1},
    'International': {0, 1}
}

# Define valid ranges for numerical features
numerical_valid_ranges = {
    'Previous qualification (grade)': (0, 200),
    'Admission grade': (0, 200),
    'Curricular units 1st sem (grade)': (0, 20),
    'Curricular units 2nd sem (grade)': (0, 20),
    'Age at enrollment': (0, 100)
}

# Outlier detection results
outliers_list = []

print("\n1. CATEGORICAL FEATURE OUTLIERS (Invalid Categories):")
print("-" * 50)

available_categorical = [col for col in categorical_valid_ranges.keys() if col in df.columns]
print(f"Available categorical features for validation: {len(available_categorical)}")

for feature in available_categorical:
    valid_values = categorical_valid_ranges[feature]
    invalid_mask = ~df[feature].isin(valid_values)
    invalid_count = invalid_mask.sum()
    
    if invalid_count > 0:
        invalid_indices = df[invalid_mask].index.tolist()
        invalid_values_found = df.loc[invalid_mask, feature].unique()
        
        print(f"‚ùå {feature}: {invalid_count} outliers found")
        print(f"   Invalid values: {invalid_values_found}")
        
        for idx in invalid_indices[:3]:
            outlier_value = df.loc[idx, feature]
            outliers_list.append({
                'Row Index': idx,
                'Feature': feature,
                'Value': outlier_value,
                'Reason': f"Invalid categorical value. Valid range: {valid_values}",
                'Type': 'Categorical'
            })
    else:
        print(f"‚úÖ {feature}: No outliers")

print("\n2. NUMERICAL FEATURE OUTLIERS (Statistical Methods):")
print("-" * 50)

continuous_features = [
    'Previous qualification (grade)', 'Admission grade', 
    'Curricular units 1st sem (grade)', 'Curricular units 2nd sem (grade)',
    'Unemployment rate', 'Inflation rate', 'GDP', 'Age at enrollment'
]

available_numerical = [col for col in continuous_features if col in df.columns]
print(f"Available numerical features: {len(available_numerical)}")

for feature in available_numerical:
    print(f"\nüìä {feature}:")
    feature_data = df[feature].dropna()
    
    if len(feature_data) > 10:
        # IQR method
        Q1 = feature_data.quantile(0.25)
        Q3 = feature_data.quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        
        # Find outliers
        iqr_outliers = feature_data[(feature_data < lower_bound) | (feature_data > upper_bound)]
        
        # Check against valid ranges
        valid_outliers = []
        if feature in numerical_valid_ranges:
            min_val, max_val = numerical_valid_ranges[feature]
            for idx in iqr_outliers.index:
                value = df.loc[idx, feature]
                if value < min_val or value > max_val:
                    valid_outliers.append(idx)
        else:
            valid_outliers = list(iqr_outliers.index)
        
        if valid_outliers:
            print(f"‚ùå {len(valid_outliers)} outliers")
            print(f"   Range: [{feature_data.min():.2f}, {feature_data.max():.2f}]")
            print(f"   IQR bounds: [{lower_bound:.2f}, {upper_bound:.2f}]")
            
            for idx in valid_outliers[:3]:
                value = df.loc[idx, feature]
                outliers_list.append({
                    'Row Index': idx,
                    'Feature': feature,
                    'Value': value,
                    'Reason': f"Statistical outlier (IQR bounds: [{lower_bound:.2f}, {upper_bound:.2f}])",
                    'Type': 'Numerical'
                })
        else:
            print(f"‚úÖ No outliers")
    else:
        print(f"‚ö†Ô∏è  Insufficient data")

print(f"\nüìã TOTAL OUTLIERS IDENTIFIED: {len(outliers_list)}")

if outliers_list:
    outliers_df = pd.DataFrame(outliers_list)
    print(f"\nFirst 10 outliers:")
    print(outliers_df.head(10).to_string(index=False))

# ==========================
# d. OUTLIER HANDLING
# ==========================
print("\n\nd. OUTLIER HANDLING")
print("=" * 50)

# Create a copy of the dataframe before handling outliers
df_cleaned = df.copy()
outliers_handled = 0

print("\nOUTLIER HANDLING STRATEGIES:")
print("-" * 30)

for outlier in outliers_list:
    feature = outlier['Feature']
    row_idx = outlier['Row Index']
    original_value = outlier['Value']
    
    if outlier['Type'] == 'Categorical':
        # For categorical outliers, use mode (most frequent value)
        mode_value = df_cleaned[feature].mode()
        if len(mode_value) > 0:
            new_value = mode_value[0]
            df_cleaned.loc[row_idx, feature] = new_value
            print(f"‚úÖ Row {row_idx}, {feature}: {original_value} ‚Üí {new_value} (mode)")
            outliers_handled += 1
        else:
            print(f"‚ö†Ô∏è  Could not handle outlier in row {row_idx}, {feature}: No mode available")
    
    elif outlier['Type'] == 'Numerical':
        # For numerical outliers, use median
        median_value = df_cleaned[feature].median()
        df_cleaned.loc[row_idx, feature] = median_value
        print(f"‚úÖ Row {row_idx}, {feature}: {original_value:.2f} ‚Üí {median_value:.2f} (median)")
        outliers_handled += 1

print(f"\nüìä OUTLIER HANDLING SUMMARY:")
print(f"   Total outliers identified: {len(outliers_list)}")
print(f"   Outliers successfully handled: {outliers_handled}")

# Verify outlier handling
print(f"\nüîç VERIFICATION AFTER OUTLIER HANDLING:")
print("-" * 40)

# Check if outliers still exist in Marital status
marital_outliers_after = ~df_cleaned['Marital status'].isin(categorical_valid_ranges['Marital status']).sum()
print(f"Marital status outliers after handling: {marital_outliers_after}")

# ==========================
# e. DATA QUALITY REPORT
# ==========================
print("\n\ne. DATA QUALITY REPORT")
print("=" * 50)

print(f"\nüìà DATA QUALITY METRICS:")
print(f"   Original dataset shape: {df.shape}")
print(f"   Cleaned dataset shape: {df_cleaned.shape}")
print(f"   Missing values (original): {df.isnull().sum().sum()}")
print(f"   Missing values (cleaned): {df_cleaned.isnull().sum().sum()}")
print(f"   Outliers identified: {len(outliers_list)}")
print(f"   Outliers handled: {outliers_handled}")

# Data quality score calculation
total_cells = df_cleaned.shape[0] * df_cleaned.shape[1]
quality_issues = df_cleaned.isnull().sum().sum() + outliers_handled
quality_score = ((total_cells - quality_issues) / total_cells) * 100

print(f"   Data quality score: {quality_score:.2f}%")

# ==========================
# c. DESCRIPTIVE ANALYSIS (on cleaned data)
# ==========================
print("\n\nc. DESCRIPTIVE ANALYSIS (CLEANED DATA)")
print("=" * 50)

print(f"\n1. DATASET OVERVIEW:")
print(f"   Records: {len(df_cleaned):,}")
print(f"   Features: {len(df_cleaned.columns)}")
print(f"   Memory: {df_cleaned.memory_usage(deep=True).sum() / 1024**2:.1f} MB")

# Target analysis
if 'Target' in df_cleaned.columns:
    print(f"\n2. TARGET DISTRIBUTION:")
    target_dist = df_cleaned['Target'].value_counts()
    for target, count in target_dist.items():
        percent = (count / len(df_cleaned)) * 100
        print(f"   {target}: {count} ({percent:.1f}%)")

print(f"\n3. NUMERICAL FEATURES SUMMARY (CLEANED):")
if available_numerical:
    print(df_cleaned[available_numerical].describe())

print(f"\n4. CATEGORICAL FEATURES CARDINALITY (CLEANED):")
if available_categorical:
    for feature in available_categorical[:5]:  # Show first 5
        unique_count = df_cleaned[feature].nunique()
        print(f"   {feature}: {unique_count} unique values")

# Show before and after comparison for features with handled outliers
if outliers_list:
    print(f"\n5. OUTLIER HANDLING COMPARISON:")
    print("-" * 35)
    
    affected_features = set([outlier['Feature'] for outlier in outliers_list])
    for feature in affected_features:
        if feature in df.columns:
            original_unique = df[feature].unique()
            cleaned_unique = df_cleaned[feature].unique()
            
            print(f"\n{feature}:")
            print(f"   Original unique values: {sorted(original_unique)}")
            print(f"   Cleaned unique values:  {sorted(cleaned_unique)}")

print(f"\n‚úÖ TASK 1 COMPLETED:")
print(f"   - Original dataset shape: {df.shape}")
print(f"   - Cleaned dataset shape: {df_cleaned.shape}")
print(f"   - Missing values: {df_cleaned.isnull().sum().sum()}")
print(f"   - Outliers identified: {len(outliers_list)}")
print(f"   - Outliers handled: {outliers_handled}")
print(f"   - Data quality score: {quality_score:.2f}%")
print(f"   - Data types: {dict(df_cleaned.dtypes.value_counts())}")

# Save cleaned dataset
try:
    df_cleaned.to_csv(r"C:\Users\Molefi\Desktop\ProjectAI\cleaned_data.csv", index=False)
    print(f"\nüíæ Cleaned dataset saved as 'cleaned_data.csv'")
except Exception as e:
    print(f"\n‚ö†Ô∏è  Could not save cleaned dataset: {e}")

# Return the cleaned dataframe for further processing
print(f"\nüéØ READY FOR TASK 2: FEATURE ENGINEERING")